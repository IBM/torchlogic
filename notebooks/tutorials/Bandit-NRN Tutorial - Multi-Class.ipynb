{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc1cf98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip uninstall /Path/to/the/whl/file/torchlogic-0.0.1-py3-none-any.whl -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99bde8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install /Path/to/the/whl/file/torchlogic-0.0.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bd57348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3b584d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Choices for a categorical distribution should be a tuple\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"To copy construct from a tensor, it is recommended\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"IProgress not found\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Precision is ill-defined\")\n",
    "\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import softmax\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, roc_auc_score\n",
    "\n",
    "from torchlogic.models import BanditNRNClassifier\n",
    "from torchlogic.utils.trainers import BanditNRNTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04f0b590-a11f-4095-ba69-c7edfc9fcfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want the logs from Bandit-RRN training\n",
    "\n",
    "# from carrot.logger import Logger\n",
    "\n",
    "# log_config = 'configs/logging.yaml'\n",
    "# log_dir = 'logs'\n",
    "# logger = Logger.get(log_config, log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32cc9de",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79426bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_iris()\n",
    "data.target[[10, 25, 50]]\n",
    "data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5378c6d",
   "metadata": {},
   "source": [
    "# Prepare Bandit-RRN Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a00c989",
   "metadata": {},
   "source": [
    "A dataset for the Bandit-RRN algorithm in torchlogic must return a dictionary of the following form:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'features': [N_FEATURES], 'target': [N_TARGETS], 'sample_idx': [1]\n",
    "}\n",
    "```\n",
    "\n",
    "- The `features` key contains a tensor of the features used for prediction.  Feature must be numeric and scaled between 0 and 1.\n",
    "\n",
    "- The `target` key must contain a tensor of the targets, with the values of 0 or 1 for each target.\n",
    "\n",
    "- The `sample_idx` key must contain a tensor of the row number in the data corresponding to that sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855fbe56",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9863924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()\n",
    "X = mms.fit_transform(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63d35d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(data.target).astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51b54a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "###############################################################################################################################\n",
    "# NOTE: The iris dataset is very small.  The validation set is particularly small in this case so we have enough training data.\n",
    "# For real-world applications a larger test size is likely required.\n",
    "###############################################################################################################################\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.11, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba908ac4",
   "metadata": {},
   "source": [
    "## Define PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51d41c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BanditRRNDataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            X: np.array,\n",
    "            y: np.array\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Dataset suitable for BanditRRN model from torchlogic\n",
    "\n",
    "        Args:\n",
    "            X (np.array): features data scaled to [0, 1]\n",
    "            y (np.array): target data of classes 0, 1\n",
    "        \"\"\"\n",
    "        super(BanditRRNDataset, self).__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.sample_idx = np.arange(X.shape[0])  # index of samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = torch.from_numpy(self.X[idx, :]).float()\n",
    "        target = torch.from_numpy(self.y[idx, :])\n",
    "        return {'features': features, 'target': target, 'sample_idx': idx}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5651ce",
   "metadata": {},
   "source": [
    "## Instantiate Datasets and Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6a6c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BanditRRNDataset(X=X_train, y=y_train)\n",
    "val_dataset = BanditRRNDataset(X=X_val, y=y_val)\n",
    "test_dataset = BanditRRNDataset(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b8c779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "def create_holdout_samplers(train_dataset, pct=0.2):\n",
    "    train_size = len(train_dataset)\n",
    "    indices = list(range(train_size))\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    train_holdout_split_index = int(np.floor(pct * train_size))\n",
    "    train_idx, train_holdout_idx = indices[train_holdout_split_index:], indices[:train_holdout_split_index]\n",
    "    \n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    train_holdout_sampler = SubsetRandomSampler(train_holdout_idx)\n",
    "    \n",
    "    return train_sampler, train_holdout_sampler\n",
    "\n",
    "train_sampler, train_holdout_sampler = create_holdout_samplers(train_dataset)\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_dataset, batch_size=32, generator=g, sampler=train_sampler,\n",
    "    pin_memory=False, persistent_workers=False, num_workers=0  # very important to optimize these settings in production\n",
    ")\n",
    "train_holdout_dl = DataLoader(\n",
    "    train_dataset, batch_size=32, generator=g, sampler=train_holdout_sampler,\n",
    "    pin_memory=False, persistent_workers=False, num_workers=0  # very important to optimize these settings in production\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    val_dataset, batch_size=32, generator=g, \n",
    "    pin_memory=False, persistent_workers=False, num_workers=0  # very important to optimize these settings in production\n",
    ")\n",
    "test_dl = DataLoader(\n",
    "    test_dataset, batch_size=32, generator=g, \n",
    "    pin_memory=False, persistent_workers=False, num_workers=0  # very important to optimize these settings in production\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170ca75e",
   "metadata": {},
   "source": [
    "# Train Bandit-RRN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4c15b9-a9e0-4276-8e9d-030e5eb3d32a",
   "metadata": {},
   "source": [
    "## Prepare the Feature Names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe726ef-8d07-4147-baa6-aace2a8cc1e6",
   "metadata": {},
   "source": [
    "To aid in the explantions of our model, we can set our feature names to natural language that represents the values of the feature.\n",
    "In the current data, each feature represents a measurement in centimeters and is scaled between 0 to 1, so represents a percentile.\n",
    "We rename each feature to describe this represenation of our data, which is then used when extracting explanations from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d441867-41bf-4825-9a70-4c30e8f06276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a29441d-b77b-4491-ae59-4845efd3940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.feature_names = [\"the sepal length in cm was\", \"the sepal width in cm was\", \n",
    "                      \"the petal length in cm was\", \"the petal width in cm was\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e623836",
   "metadata": {},
   "source": [
    "## Tune Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8425fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "class TuneParameters:\n",
    "    \n",
    "    def __init__(self, n_trials=10):\n",
    "        self.best_model = None\n",
    "        self.best_rn_val_performance = 0.0\n",
    "        self.n_trials = n_trials\n",
    "\n",
    "    def _objective(self, trial):\n",
    "\n",
    "        ########################################################################################################################\n",
    "        # NOTE: These hyper-parameter settings are specific to the iris flower dataset.  For information on generally useful\n",
    "        # ranges of hyper-parameters and their descriptions see our documentation: \n",
    "        ########################################################################################################################\n",
    "\n",
    "        # Set Parameters\n",
    "        \n",
    "        ## Reinforced Reasoning Network Parameters\n",
    "        layer_sizes = trial.suggest_categorical('layer_sizes', [(2, ), (3, ), (5, ), \n",
    "                                                                (2, 2), (3, 3), (5, 5), \n",
    "                                                                (2, 2, 2), (3, 3, 3), (5, 5, 5)])\n",
    "        n_selected_features_input = trial.suggest_int('n_selected_features_input', low=2, high=3)\n",
    "        n_selected_features_internal = trial.suggest_int('n_selected_features_internal', low=2, high=min(3, min(layer_sizes)))\n",
    "        n_selected_features_output = trial.suggest_int('n_selected_features_output', low=2, high=min(3, layer_sizes[-1]))\n",
    "        perform_prune_plateau_count = trial.suggest_int('perform_prune_plateau_count', low=1, high=1)\n",
    "        perform_prune_quantile = trial.suggest_float('perform_prune_quantile', low=0.1, high=0.9)\n",
    "        increase_prune_plateau_count = trial.suggest_int('increase_prune_plateau_count', low=0, high=20)\n",
    "        increase_prune_plateau_count_plateau_count = trial.suggest_int('increase_prune_plateau_count_plateau_count', low=10, high=30)\n",
    "        ucb_scale = trial.suggest_float('ucb_scale', low=1.0, high=2.0)\n",
    "        normal_form = trial.suggest_categorical('normal_form', ['dnf', 'cnf'])\n",
    "        prune_strategy = trial.suggest_categorical('prune_strategy', ['class', 'logic'])\n",
    "        delta = trial.suggest_float('delta', low=2.0, high=2.0)\n",
    "        bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
    "        swa = trial.suggest_categorical('swa', [True, False])\n",
    "        add_negations = trial.suggest_categorical('add_negations', [True, False])\n",
    "        weight_init = trial.suggest_float('weight_init', low=0.01, high=1.0)\n",
    "\n",
    "        ## Optimizer Parameters\n",
    "\n",
    "        ### Learning Rate\n",
    "        learning_rate = trial.suggest_float('learning_rate', low=0.01, high=0.2)\n",
    "\n",
    "        ### L1 Regularization\n",
    "        use_l1 = trial.suggest_categorical('use_l1', [True, False])\n",
    "        if use_l1:\n",
    "            l1_lambda = trial.suggest_float('l1_lambda', low=0.00001, high=0.1)\n",
    "        else:\n",
    "            l1_lambda = 0\n",
    "\n",
    "        ### Weight Decay Regularization\n",
    "        use_weight_decay = trial.suggest_categorical('use_weight_decay', [True, False])\n",
    "        if use_weight_decay:\n",
    "            weight_decay = trial.suggest_float('weight_decay', low=0.00001, high=0.1)\n",
    "        else:\n",
    "            weight_decay = 0\n",
    "\n",
    "        ### Lookahead Optimization\n",
    "        use_lookahead = trial.suggest_categorical('use_lookahead', [True, False])\n",
    "        if use_lookahead:\n",
    "            lookahead_steps = trial.suggest_int('lookahead_steps', low=5, high=10, step=1)\n",
    "            lookahead_steps_size = trial.suggest_float('lookahead_steps_size', low=0.5, high=0.8)\n",
    "        else:\n",
    "            lookahead_steps = 0\n",
    "            lookahead_steps_size = 0\n",
    "\n",
    "        ### Data Augmentation\n",
    "        # augment = trial.suggest_categorical('augment', ['CM', 'MU', 'AT', None])\n",
    "        augment = trial.suggest_categorical('augment', ['CM', 'MU', None])  # excluding Adversarial Learning because it fails on Jupyter Notebooks\n",
    "        if augment is not None:\n",
    "            augment_alpha = trial.suggest_float('augment_alpha', low=0.0, high=1.0)\n",
    "        else:\n",
    "            augment_alpha = 0\n",
    "\n",
    "        ### Early Stopping\n",
    "        early_stopping_plateau_count = trial.suggest_int('early_stopping_plateau_count', low=20, high=50, step=1)\n",
    "        \n",
    "        ## Scheulder parameters\n",
    "        t_0 = trial.suggest_int('T_0', low=2, high=10, step=1)\n",
    "        t_mult = trial.suggest_int('T_mult', low=1, high=3, step=1)\n",
    "\n",
    "        # init model\n",
    "        model = BanditNRNClassifier(\n",
    "            target_names=[x + '_label' for x in data.target_names],\n",
    "            feature_names=data.feature_names,\n",
    "            input_size=len(data.feature_names),\n",
    "            output_size=len(data.target_names),\n",
    "            layer_sizes=layer_sizes,\n",
    "            n_selected_features_input=n_selected_features_input,\n",
    "            n_selected_features_internal=n_selected_features_internal,\n",
    "            n_selected_features_output=n_selected_features_output,\n",
    "            perform_prune_quantile=perform_prune_quantile,\n",
    "            ucb_scale=ucb_scale,\n",
    "            normal_form=normal_form,\n",
    "            delta=delta,\n",
    "            prune_strategy=prune_strategy,\n",
    "            bootstrap=bootstrap,\n",
    "            swa=swa,\n",
    "            add_negations=add_negations,\n",
    "            weight_init=weight_init\n",
    "        )\n",
    "\n",
    "        epochs = 100\n",
    "        accumulation_steps = 1\n",
    "        optimizer = optim.AdamW(model.rn.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=t_0, T_mult=t_mult)\n",
    "        trainer = BanditNRNTrainer(\n",
    "            model=model,\n",
    "            loss_func=nn.BCELoss(),\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            epochs=epochs,\n",
    "            accumulation_steps=accumulation_steps,\n",
    "            l1_lambda=l1_lambda,\n",
    "            early_stopping_plateau_count=early_stopping_plateau_count,\n",
    "            perform_prune_plateau_count=perform_prune_plateau_count,\n",
    "            increase_prune_plateau_count=increase_prune_plateau_count,\n",
    "            increase_prune_plateau_count_plateau_count=increase_prune_plateau_count_plateau_count,\n",
    "            lookahead_steps=lookahead_steps,\n",
    "            lookahead_steps_size=lookahead_steps_size,\n",
    "            augment=augment,\n",
    "            augment_alpha=augment_alpha,\n",
    "            class_independent=True\n",
    "        )\n",
    "\n",
    "        # train model\n",
    "        # The trainer defaults to optimizing the validation roc_auc_score.  To optimize against a different metric pass the sklearn metric to the 'evaluation_metric' parameter\n",
    "        trainer.train(train_dl, train_holdout_dl, evaluation_metric=roc_auc_score, multi_class=True)\n",
    "        trainer.set_best_state()\n",
    "\n",
    "        # evaluate model\n",
    "        predictions, targets = trainer.model.predict(val_dl)\n",
    "        rn_val_performance = trainer.model.evaluate(\n",
    "            predictions=predictions,\n",
    "            labels=targets\n",
    "        )\n",
    "\n",
    "        if rn_val_performance > self.best_rn_val_performance:\n",
    "            self.best_rn_val_performance = rn_val_performance\n",
    "            self.best_model = copy.copy(trainer.model)\n",
    "            self.best_model.rn = copy.deepcopy(trainer.model.rn)\n",
    "\n",
    "        return rn_val_performance\n",
    "    \n",
    "    def tune(self):\n",
    "        # 3. Create a study object and optimize the objective function.\n",
    "        sampler = optuna.samplers.TPESampler(multivariate=True, group=True, seed=42)\n",
    "        study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "        study.optimize(self._objective, n_trials=self.n_trials)\n",
    "        return self.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41831d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = TuneParameters(50).tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd5a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, targets = best_model.predict(val_dl)\n",
    "# Evaluate defaults to compute AUC\n",
    "rn_val_performance = best_model.evaluate(\n",
    "    predictions=predictions,\n",
    "    labels=targets,\n",
    "    multi_class=False\n",
    ")\n",
    "class_predictions = predictions.eq(predictions.max(axis=1), axis=0).astype(int)\n",
    "predictions_probs = pd.DataFrame(softmax(predictions, axis=1), columns=data.target_names)  # CrossEntropyLoss takes logits, therefore predictions are logits\n",
    "print(\"Validation AUC:\\n\\n\", rn_val_performance)\n",
    "\n",
    "# Evaluate with a different metric\n",
    "rn_val_performance = best_model.evaluate(\n",
    "    predictions=predictions,\n",
    "    labels=targets,\n",
    "    output_metric=precision_score,\n",
    "    multi_class=True,\n",
    ")\n",
    "print(\"\\n\\nValidation Precision Score:\\n\\n\", rn_val_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7529fb59-44be-41be-9507-18472cf78702",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, targets = best_model.predict(test_dl)\n",
    "# Evaluate defaults to compute AUC\n",
    "rn_test_performance = best_model.evaluate(\n",
    "    predictions=predictions,\n",
    "    labels=targets,\n",
    "    multi_class=True\n",
    ")\n",
    "class_predictions = predictions.eq(predictions.max(axis=1), axis=0).astype(int)  \n",
    "predictions_probs = pd.DataFrame(softmax(predictions, axis=1), columns=data.target_names) # CrossEntropyLoss takes logits, therefore predictions are logits\n",
    "print(\"Test AUC:\\n\\n\", rn_test_performance)\n",
    "\n",
    "# Evaluate with a different metric\n",
    "rn_val_performance = best_model.evaluate(\n",
    "    predictions=predictions,\n",
    "    labels=targets,\n",
    "    output_metric=precision_score,\n",
    "    multi_class=True\n",
    ")\n",
    "print(\"\\n\\nTest Precision Score:\\n\\n\", rn_val_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af3a4c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probs_setosa</th>\n",
       "      <th>probs_versicolor</th>\n",
       "      <th>probs_virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.657724</td>\n",
       "      <td>0.414511</td>\n",
       "      <td>0.441087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.723561</td>\n",
       "      <td>0.394362</td>\n",
       "      <td>0.368766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.637375</td>\n",
       "      <td>0.412647</td>\n",
       "      <td>0.508080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.668060</td>\n",
       "      <td>0.404046</td>\n",
       "      <td>0.450843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.659075</td>\n",
       "      <td>0.410299</td>\n",
       "      <td>0.453163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.710396</td>\n",
       "      <td>0.393695</td>\n",
       "      <td>0.379084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.676111</td>\n",
       "      <td>0.399303</td>\n",
       "      <td>0.437005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.679505</td>\n",
       "      <td>0.388562</td>\n",
       "      <td>0.487621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.638697</td>\n",
       "      <td>0.410612</td>\n",
       "      <td>0.465825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.662932</td>\n",
       "      <td>0.406849</td>\n",
       "      <td>0.438732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.679909</td>\n",
       "      <td>0.395205</td>\n",
       "      <td>0.470892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.691002</td>\n",
       "      <td>0.404124</td>\n",
       "      <td>0.371182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.714414</td>\n",
       "      <td>0.395402</td>\n",
       "      <td>0.368086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.694021</td>\n",
       "      <td>0.404211</td>\n",
       "      <td>0.369984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.725911</td>\n",
       "      <td>0.392505</td>\n",
       "      <td>0.365390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    probs_setosa  probs_versicolor  probs_virginica\n",
       "0       0.657724          0.414511         0.441087\n",
       "1       0.723561          0.394362         0.368766\n",
       "2       0.637375          0.412647         0.508080\n",
       "3       0.668060          0.404046         0.450843\n",
       "4       0.659075          0.410299         0.453163\n",
       "5       0.710396          0.393695         0.379084\n",
       "6       0.676111          0.399303         0.437005\n",
       "7       0.679505          0.388562         0.487621\n",
       "8       0.638697          0.410612         0.465825\n",
       "9       0.662932          0.406849         0.438732\n",
       "10      0.679909          0.395205         0.470892\n",
       "11      0.691002          0.404124         0.371182\n",
       "12      0.714414          0.395402         0.368086\n",
       "13      0.694021          0.404211         0.369984\n",
       "14      0.725911          0.392505         0.365390"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e7505ed-8061-4eaf-97e5-f4cc97cc7757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.386201</td>\n",
       "      <td>0.302822</td>\n",
       "      <td>0.310978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.413084</td>\n",
       "      <td>0.297214</td>\n",
       "      <td>0.289703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.373490</td>\n",
       "      <td>0.298319</td>\n",
       "      <td>0.328191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.388694</td>\n",
       "      <td>0.298503</td>\n",
       "      <td>0.312804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.385556</td>\n",
       "      <td>0.300639</td>\n",
       "      <td>0.313806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.408742</td>\n",
       "      <td>0.297789</td>\n",
       "      <td>0.293469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.392845</td>\n",
       "      <td>0.297855</td>\n",
       "      <td>0.309299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.388657</td>\n",
       "      <td>0.290544</td>\n",
       "      <td>0.320799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.379175</td>\n",
       "      <td>0.301845</td>\n",
       "      <td>0.318980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.388616</td>\n",
       "      <td>0.300819</td>\n",
       "      <td>0.310565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.390074</td>\n",
       "      <td>0.293428</td>\n",
       "      <td>0.316499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.403733</td>\n",
       "      <td>0.303044</td>\n",
       "      <td>0.293223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.410822</td>\n",
       "      <td>0.298612</td>\n",
       "      <td>0.290566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.404591</td>\n",
       "      <td>0.302799</td>\n",
       "      <td>0.292610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.414286</td>\n",
       "      <td>0.296827</td>\n",
       "      <td>0.288887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      setosa  versicolor  virginica\n",
       "0   0.386201    0.302822   0.310978\n",
       "1   0.413084    0.297214   0.289703\n",
       "2   0.373490    0.298319   0.328191\n",
       "3   0.388694    0.298503   0.312804\n",
       "4   0.385556    0.300639   0.313806\n",
       "5   0.408742    0.297789   0.293469\n",
       "6   0.392845    0.297855   0.309299\n",
       "7   0.388657    0.290544   0.320799\n",
       "8   0.379175    0.301845   0.318980\n",
       "9   0.388616    0.300819   0.310565\n",
       "10  0.390074    0.293428   0.316499\n",
       "11  0.403733    0.303044   0.293223\n",
       "12  0.410822    0.298612   0.290566\n",
       "13  0.404591    0.302799   0.292610\n",
       "14  0.414286    0.296827   0.288887"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e8eda1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probs_setosa</th>\n",
       "      <th>probs_versicolor</th>\n",
       "      <th>probs_virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    probs_setosa  probs_versicolor  probs_virginica\n",
       "0              1                 0                0\n",
       "1              1                 0                0\n",
       "2              1                 0                0\n",
       "3              1                 0                0\n",
       "4              1                 0                0\n",
       "5              1                 0                0\n",
       "6              1                 0                0\n",
       "7              1                 0                0\n",
       "8              1                 0                0\n",
       "9              1                 0                0\n",
       "10             1                 0                0\n",
       "11             1                 0                0\n",
       "12             1                 0                0\n",
       "13             1                 0                0\n",
       "14             1                 0                0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d57427ac-e8b1-4740-b61d-5ad9d6e858d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa_label</th>\n",
       "      <th>versicolor_label</th>\n",
       "      <th>virginica_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    setosa_label  versicolor_label  virginica_label\n",
       "0              0                 1                0\n",
       "1              1                 0                0\n",
       "2              0                 0                1\n",
       "3              0                 1                0\n",
       "4              0                 1                0\n",
       "5              1                 0                0\n",
       "6              0                 1                0\n",
       "7              0                 0                1\n",
       "8              0                 1                0\n",
       "9              0                 1                0\n",
       "10             0                 0                1\n",
       "11             1                 0                0\n",
       "12             1                 0                0\n",
       "13             1                 0                0\n",
       "14             1                 0                0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b127fa",
   "metadata": {},
   "source": [
    "# Inspecting the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16c882a",
   "metadata": {},
   "source": [
    "### Global Explain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9292d6",
   "metadata": {},
   "source": [
    "A global explanation prints the logic learned for each class.  The `quantile` parameter is the percent of the model you would like to be explained.\n",
    "\n",
    "We represent our features as values scaled between 0 and 1.  Therefore, we intepret the explanations to mean that large values for a particular feature represent `truthiness` of a predicate, while small values represent `falseness` of a predicate.\n",
    "\n",
    "For example, the following logic for the class `setosa`:\n",
    "\n",
    "```\n",
    "A flower is in the setosa class because: \n",
    "AND(\n",
    "    NOT(AND(\n",
    "            sepal width (cm) >= 0.77405,\n",
    "            petal length (cm) >= 0.4397)),\n",
    "    NOT(OR(\n",
    "            AND(\n",
    "            sepal width (cm) >= 0.67788,\n",
    "            petal length (cm) >= 0.20122),\n",
    "            NOT(sepal width (cm) >= 0.48579))))\n",
    "```\n",
    "\n",
    "The `logic` from above is intepreted as:\n",
    "\n",
    "```\n",
    "When BOTH of the following are true the class is \"setosa\":\n",
    "    1. The flower has a sepal width below the transformed value of 0.77, and has a petal length below the transformed value of 0.44.\n",
    "    2. The flower has a sepal width below the transformed value of 0.68 and a petal length below the transformed value of 0.20; OR the flower has a sepal width above the transformed value of 0.49.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e547f1ba-2e53-4640-b6ff-6c54581e5569",
   "metadata": {},
   "source": [
    "#### Print Types\n",
    "\n",
    "The explanation and printing methods can all be set to use different `print_type` parameters.  Each will produce a different style of explanation that may be used for different end-users.\n",
    "\n",
    "`logical`: produces a logic statement format such as:\n",
    "\n",
    "    AND(x1, x2)\n",
    "    \n",
    "`logical-natural`: produces a natural language formatted nested tree format, such as:\n",
    "\n",
    "    the following are TRUE:\n",
    "        - x1\n",
    "        - x2\n",
    "        \n",
    "`natural`: produces a natural lanugage paragraph indicating the most important logics, to the least important logics, such as:\n",
    "\n",
    "    Each one of the following must be met.  x1, and x2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355a43c8-d136-4866-944d-05d32a18e8ce",
   "metadata": {},
   "source": [
    "### Controlling explanation outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9def35c6-d9fc-4a4a-a113-47d248cd447d",
   "metadata": {},
   "source": [
    "There are several options to control the output of our explanations that enable us to produce the right type of explanation output for our particular use case.  Some dimensions of control include:\n",
    "\n",
    "- quantile: When less than 1.0, the most important (i.e. predictive) logic in the model is exposed.  The value corresponds to the quantile of weights that should be included, e.g. 0.4 corresponds to including logic with weights in the top 0.4 quantile or above.\n",
    "- expkain_type: Can be set to 'both', 'positive' or 'negative'.  Both includes both positive and negative relations, i.e. X and NOT(X).  Optionally, we can subset the explaination to only those logics that are positively or negatively related to our target.\n",
    "- print_type: Can be set to 'natural' or 'logical'.  Natural explanations are produced using more natural language, while learned logical represenations show the structure of the logic in a concise logical form.\n",
    "- ignore_uninformative: Can be True or False.  If set to True, then logics that don't provide information about why a prediction is made are excluded.  This could be a logic like, the value of X is greater than the minimum value of X -- all data points will be true.\n",
    "- rounding_precision: This integer controls how to round the decision boundaries of each logic.\n",
    "- show_bounds: Can be True or False.  In some cases it may be uninformative or unnecessary to show the decision boundaries of the logic.  For example, if all features are boolean then decision boundaries for each logic are unnecessary.\n",
    "- inverse_transform: This argument takes the inverse transformation for input features.  If supplied, the bounds from logic will show in the untransformed space, otherwise the bounds will be in the transformed space (i.e. between 0 and 1).\n",
    "\n",
    "To demonstrate an example of this control, we reduce the size of the long model explanation above using the quantile parameter.  We see that we can explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d0d0a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A flower is in the setosa because: \n",
      "\n",
      "\n",
      "AND \n",
      "\tNOT \n",
      "\t\tOR \n",
      "\t\t\tThe petal length in cm was >= 6.9\n",
      "\t\t\tNOT \n",
      "\t\t\t\tThe petal width in cm was >= 0.1\n",
      "\tOR \n",
      "\t\tNOT \n",
      "\t\t\tThe petal length in cm was >= 6.9\n",
      "\t\tNOT \n",
      "\t\t\tThe petal width in cm was >= 2.5\n",
      "\t\tNOT \n",
      "\t\t\tThe sepal width in cm was >= 4.4\n",
      "\n",
      "A flower is in the versicolor because: \n",
      "\n",
      "\n",
      "OR \n",
      "\tNOT \n",
      "\t\tThe petal width in cm was >= 0.1\n",
      "\tNOT \n",
      "\t\tThe sepal length in cm was >= 4.3\n",
      "\tNOT \n",
      "\t\tThe sepal width in cm was >= 2.0\n",
      "\n",
      "A flower is in the virginica because: \n",
      "\n",
      "\n",
      "AND \n",
      "\tNOT \n",
      "\t\tThe sepal width in cm was >= 2.0\n",
      "\tOR \n",
      "\t\tThe petal length in cm was >= 5.58695\n",
      "\t\tThe petal width in cm was >= 0.8709\n",
      "\t\tThe petal width in cm was >= 1.48097\n"
     ]
    }
   ],
   "source": [
    "print(best_model.explain(\n",
    "    quantile=1.0,\n",
    "    required_output_thresholds=np.array(0.5),\n",
    "    explain_type='both',\n",
    "    print_type='logical', \n",
    "    explanation_prefix=\"A flower is in the\",\n",
    "    target_names=data.target_names,\n",
    "    ignore_uninformative=True,\n",
    "    rounding_precision=5,\n",
    "    inverse_transform=mms.inverse_transform\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c4f07b9-a41a-43d7-997e-209976781a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A flower is in the setosa because: \n",
      "\n",
      "\n",
      "It was not true that \n",
      "\tThe petal length in cm was >= 6.9\n",
      "\n",
      "A flower is in the versicolor because: \n",
      "\n",
      "\n",
      "It was not true that \n",
      "\tThe petal width in cm was >= 0.1\n",
      "\n",
      "A flower is in the virginica because: \n",
      "\n",
      "\n",
      "It was not true that \n",
      "\tThe sepal width in cm was >= 2.0\n"
     ]
    }
   ],
   "source": [
    "print(best_model.explain(\n",
    "    quantile=0.4,\n",
    "    required_output_thresholds=np.array(0.5),\n",
    "    explain_type='both',\n",
    "    print_type='logical-natural', \n",
    "    explanation_prefix=\"A flower is in the\",\n",
    "    target_names=data.target_names,\n",
    "    ignore_uninformative=True,\n",
    "    rounding_precision=5,\n",
    "    show_bounds=True,\n",
    "    inverse_transform=mms.inverse_transform\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a47d5d",
   "metadata": {},
   "source": [
    "### Printing the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80350a16",
   "metadata": {},
   "source": [
    "We can inspect the weights the model learned for each logic to see how important they are to the overall prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb1326c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REASONING NETWORK MODEL FOR: setosa\n",
      "Logic at depth 2: NOT(the petal width in cm was >= 0.0), NOT(the sepal width in cm was >= 0.43456), the petal length in cm was >= 0.14846\n",
      "output: tensor([0.0339, 0.0417, 0.5000])\n",
      "\n",
      "Logic at depth 1: ['NOT(OR(NOT(the petal width in cm was >= 0.0), NOT(the sepal width in cm was >= 0.43456), the petal length in cm was >= 0.14846))']\n",
      "weights: tensor([ 0.1858, -0.1280, -0.3253])\n",
      "output: 0.7083703279495239\n",
      "required_threshold: 0.6870833039283752\n",
      "\n",
      "Logic at depth 2: NOT(the petal length in cm was >= 0.91488), NOT(the petal width in cm was >= 0.62991), NOT(the sepal width in cm was >= 1.0)\n",
      "output: tensor([0.0417, 0.0339, 0.5000])\n",
      "\n",
      "Logic at depth 1: ['OR(NOT(the petal length in cm was >= 0.91488), NOT(the petal width in cm was >= 0.62991), NOT(the sepal width in cm was >= 1.0))']\n",
      "weights: tensor([-0.0535, -0.0357, -0.0303])\n",
      "output: 0.10098778456449509\n",
      "required_threshold: 0.06949496269226074\n",
      "\n",
      "Logic at depth 0: ['AND(NOT(OR(NOT(the petal width in cm was >= 0.0), NOT(the sepal width in cm was >= 0.43456), the petal length in cm was >= 0.14846)), OR(NOT(the petal length in cm was >= 0.91488), NOT(the petal width in cm was >= 0.62991), NOT(the sepal width in cm was >= 1.0)))']\n",
      "weights: tensor([-0.3302,  0.2232])\n",
      "output: 0.7030056118965149\n",
      "required_threshold: 0.6959755420684814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model.print_samples(\n",
    "    val_dataset[idx]['features'].unsqueeze(0),\n",
    "    quantile=1.0,\n",
    "    target_names=data.target_names, \n",
    "    explain_type='both',\n",
    "    print_type='logical',\n",
    "    ignore_uninformative=False,\n",
    "    rounding_precision=5,\n",
    "    # inverse_transform=mms.inverse_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf22a50e-ac0d-4813-8188-562cf1225680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REASONING NETWORK MODEL FOR: setosa\n",
      "Logic at depth 2: NOT(the petal width in cm was >= 0.0), the petal length in cm was >= 1.0\n",
      "output: tensor([0.1855, 0.7307, 0.0000])\n",
      "\n",
      "Logic at depth 1: ['NOT(OR(NOT(the petal width in cm was >= 0.0), the petal length in cm was >= 1.0))']\n",
      "weights: tensor([ 0.1858, -0.1280, -0.3253])\n",
      "output: 0.16345000267028809\n",
      "required_threshold: 0.16192841529846191\n",
      "\n",
      "Logic at depth 2: NOT(the petal length in cm was >= 1.0), NOT(the petal width in cm was >= 1.0), NOT(the sepal width in cm was >= 1.0)\n",
      "output: tensor([1., 1., 1.])\n",
      "\n",
      "Logic at depth 1: ['OR(NOT(the petal length in cm was >= 1.0), NOT(the petal width in cm was >= 1.0), NOT(the sepal width in cm was >= 1.0))']\n",
      "weights: tensor([-0.0535, -0.0357, -0.0303])\n",
      "output: 0.0\n",
      "required_threshold: 0.0\n",
      "\n",
      "Logic at depth 0: ['AND(NOT(OR(NOT(the petal width in cm was >= 0.0), the petal length in cm was >= 1.0)), OR(NOT(the petal length in cm was >= 1.0), NOT(the petal width in cm was >= 1.0), NOT(the sepal width in cm was >= 1.0)))']\n",
      "weights: tensor([-0.3302,  0.2232])\n",
      "output: 0.5005000233650208\n",
      "required_threshold: 0.5\n",
      "\n",
      "REASONING NETWORK MODEL FOR: versicolor\n",
      "Logic at depth 2: \n",
      "output: tensor([0., 0., 1.])\n",
      "\n",
      "Logic at depth 2: NOT(the petal width in cm was >= 0.0), NOT(the sepal length in cm was >= 0.0), NOT(the sepal width in cm was >= 0.0)\n",
      "output: tensor([0., 0., 0.])\n",
      "\n",
      "Logic at depth 1: ['OR(NOT(the petal width in cm was >= 0.0), NOT(the sepal length in cm was >= 0.0), NOT(the sepal width in cm was >= 0.0))']\n",
      "weights: tensor([-0.0034, -0.0994, -0.0386])\n",
      "output: 0.5789700150489807\n",
      "required_threshold: 0.5781263709068298\n",
      "\n",
      "Logic at depth 0: ['OR(NOT(the petal width in cm was >= 0.0), NOT(the sepal length in cm was >= 0.0), NOT(the sepal width in cm was >= 0.0))']\n",
      "weights: tensor([-0.3825,  0.5932])\n",
      "output: 0.5005000233650208\n",
      "required_threshold: 0.5\n",
      "\n",
      "REASONING NETWORK MODEL FOR: virginica\n",
      "Logic at depth 2: the petal length in cm was >= 0.77745, the petal width in cm was >= 0.32121, the petal width in cm was >= 0.5754\n",
      "output: tensor([0.7775, 0.3212, 0.5754])\n",
      "\n",
      "Logic at depth 1: ['OR(the petal length in cm was >= 0.77745, the petal width in cm was >= 0.32121, the petal width in cm was >= 0.5754)']\n",
      "weights: tensor([0.0746, 0.1807, 0.1008])\n",
      "output: 0.17574000358581543\n",
      "required_threshold: 0.17408818006515503\n",
      "\n",
      "Logic at depth 2: NOT(the sepal width in cm was >= 0.0)\n",
      "output: tensor([0., 0., 0.])\n",
      "\n",
      "Logic at depth 1: ['NOT(the sepal width in cm was >= 0.0)']\n",
      "weights: tensor([-0.1352,  0.0438,  0.0517])\n",
      "output: 0.30188998579978943\n",
      "required_threshold: 0.3004910945892334\n",
      "\n",
      "Logic at depth 0: ['AND(NOT(the sepal width in cm was >= 0.0), OR(the petal length in cm was >= 0.77745, the petal width in cm was >= 0.32121, the petal width in cm was >= 0.5754))']\n",
      "weights: tensor([0.3030, 0.3578])\n",
      "output: 0.5005000233650208\n",
      "required_threshold: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model.print(\n",
    "    quantile=1.0,\n",
    "    required_output_thresholds=torch.tensor(0.5),\n",
    "    explain_type='both',\n",
    "    print_type='logical', \n",
    "    target_names=data.target_names,\n",
    "    ignore_uninformative=False,\n",
    "    rounding_precision=5,\n",
    "    # inverse_transform=mms.inverse_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72024d6-af19-4908-84ce-2e139ead26cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
